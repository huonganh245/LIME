## LIME - Local Interpretable Model-Agnostic Explanations
#Interpretability
Interpretability is a term every data scientist today should familiarize themselves with. This is because we need to know if we can rely on the results we get from using a machine learning model. In machine learning feeding a model data and training it to predict something for you is the process used today to get answers, and often impressive answers due to how powerful these models are. But that does not mean it can be trusted. 

When running a machine learning model, the model learns and gives you answers, for example in the form of classification. If the model you run gives you great answers, then why not just be happy with the results and ignore the process of how a conclusion was made? In order to know if we can trust the results or not, it is important to understand how the model has learned and why it made the decision it did.
 
This is where model interpretability comes in the picture. Model interpretability is how humans understand and learn how a machine learning model or artificial neuron network reaches the conclusions it does, what features are behind a decision. Therefore it is important for humans to understand how the model works and learns in order to trust the results it gives. 

For example, if you have a collection of pictures with either a dog or a moose and want to classify them with a machine learning model. The model is supposed to learn the features of the animals, but letâ€™s say you took all the pictures of dogs in an indoor setting while all the moose was in the forest. Here you run the risk of the model classifying based on the surroundings of the animal instead of the features of it. So if you have a dog in the forest the picture would be classified as a moose. Therefore it is important to understand how a model reached the conclusions it did to give credibility to the results.
 
So hopefully, for Christmas, Santa won't trust his prediction if it says you are getting coal this year, while we all know you have been good.

![alt text](https://drive.google.com/file/d/1eiZLV2fZxesUyMyEZOphgcH70e3os1rJ/view?usp=sharing)
